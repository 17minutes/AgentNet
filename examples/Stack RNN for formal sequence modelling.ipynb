{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/Theano-0.8.0rc1-py2.7.egg/theano/tensor/signal/downsample.py:5: UserWarning: downsample module has been moved to the pool module.\n",
      "  warnings.warn(\"downsample module has been moved to the pool module.\")\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "#theano imports\n",
    "import lasagne\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import sys\n",
    "sys.setrecursionlimit(100000)\n",
    "floatX = theano.config.floatX\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stack-augmented RNN\n",
    "![caption](https://usercontent1.hubstatic.com/6172838_f260.jpg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reproduces experiment from article http://arxiv.org/abs/1503.01007"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task and architecture\n",
    "\n",
    "__The task__ is to train an RNN to generate sequences from expression `|`$ a^n b^m c^{n+m} $\n",
    " * n and m are integers\n",
    " * Performance metrics:\n",
    "  * Correct format - `|`, some a, some b, some c\n",
    "     * ||aaacbbcba would be an example of incorrect one\n",
    "  * Number of C letters to be as close to sum of A band B letters as possible\n",
    "     * Ideally, #c = #a + #b\n",
    "     \n",
    "\n",
    "Model we use:\n",
    " * Stack-augmented RNN\n",
    " \n",
    "Trained as a language model (predicting next symbols given preceding history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequence generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_sequence(batch_size = 10,crop_length = 100 ):\n",
    "    \"\"\"\n",
    "    Generates sequence from pattern [0  1*n 2*m 3*(n+m)]\n",
    "    \"\"\"\n",
    "    sequences=[]\n",
    "    for i in range(batch_size):\n",
    "        seq = [0]\n",
    "        while len(seq) < crop_length:\n",
    "            n,m = np.random.randint(1,15,2)\n",
    "        \n",
    "            seq += [0]+ [1]*n+[2]*m+[3]*(n+m)\n",
    "        seq = seq[:crop_length]\n",
    "        sequences.append(seq)\n",
    "    return np.array(sequences,dtype='int32')\n",
    "\n",
    "alphabet = np.array(list('|abc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#quality evaluation\n",
    "from operator import add\n",
    "import re\n",
    "def get_metrics(gen_sequences,alphabet):    \n",
    "    strings = map(lambda v:reduce(add,v), map(alphabet.__getitem__,gen_sequences))\n",
    "    \n",
    "    #at least one complete string\n",
    "    strings = filter(lambda v: '|' in v,strings)\n",
    "    \n",
    "    #cut off last unfinished string, if any\n",
    "    \n",
    "    strings = map(lambda v: v[:-1-v[::-1].index('|')],strings)\n",
    "    \n",
    "    all_strings = '|'.join(strings)\n",
    "    \n",
    "    \n",
    "    \n",
    "    seqs = filter(len,all_strings.split('|'))\n",
    "    \n",
    "    matches = map(lambda seq:re.match(r\"^a+b+c+\",seq),seqs)\n",
    "    \n",
    "    is_correct = map( lambda seq,m: m is not None and m.pos==0 and m.endpos == len(seq), \n",
    "                        seqs, matches)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    correct_seqs = np.array(seqs)[np.array(is_correct,dtype='bool')]\n",
    "    \n",
    "    seqs_error = map(lambda s: s.count('a')+ s.count('b') - s.count('c'),correct_seqs)\n",
    "    \n",
    "    return np.mean(is_correct), np.mean(np.abs(seqs_error))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 586 µs, sys: 126 µs, total: 712 µs\n",
      "Wall time: 1.32 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['||aaaaaaaabbbbbbbbbbbbbccccccccccccccccccccc|aaaaaaaaabcccccccccc|aaaaaaaaaaaaabcccccccccccccc|aaaaa',\n",
       " '||abbbbbbbbbbbcccccccccccc|aabbbbcccccc|aaaaaaaaaaaabbbbbbbbbbbbcccccccccccccccccccccccc|aaaaaaabbbb',\n",
       " '||aaaaaaaaaaaabbbbbccccccccccccccccc|aaabbbbbbbbbbbbbcccccccccccccccc|aaaaaaaaaabbbbbbbbbbbbcccccccc',\n",
       " '||aaaaaaaaaaaabbbccccccccccccccc|abbbbbbbbbbbbbbccccccccccccccc|aaaaaaaaaabbbbcccccccccccccc|aaaaaaa',\n",
       " '||aaaaaaaaaaaaaabbbbbbbbbbcccccccccccccccccccccccc|aaaaaabbbbcccccccccc|aaaaabbbbbbbbbbbbbbccccccccc']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "map(''.join,map(alphabet.__getitem__,generate_sequence(5,100)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# length of training/generation sequence\n",
    "SEQ_LENGTH = 100\n",
    "\n",
    "# Sequences in a minibatch\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "# Total epochs\n",
    "N_EPOCHS = 5000\n",
    "\n",
    "#how often to print metrics\n",
    "REPORT_RATE = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Reference sequences for training\n",
    "sequences_batch = T.matrix(dtype=\"int32\",name=\"reference_sequences\")\n",
    "\n",
    "#Batch size (theano expression)\n",
    "batch_size = sequences_batch.shape[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define RNN\n",
    "\n",
    "A \"simple\" scheme of what was there in the paper, followed exactly by the code below\n",
    "\n",
    "* Time goes from left to right\n",
    "* Layers start at the bottom and go up\n",
    "* memory states are green, memory updates are purple\n",
    "* inputs and outputs are blue traingles\n",
    "* transformations are in pale yellow\n",
    "\n",
    "![canvas](http://s32.postimg.org/vefrk7vqt/stack_gru.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import DenseLayer, ConcatLayer, InputLayer, EmbeddingLayer\n",
    "\n",
    "import agentnet\n",
    "from agentnet.resolver import ProbablisticResolver\n",
    "\n",
    "from agentnet.agent import Generator\n",
    "from agentnet.memory import GRUMemoryLayer, StackAugmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#input letter goes here\n",
    "output_shape = (None,)\n",
    "observation_layer = InputLayer(output_shape,name=\"obs_input\")\n",
    "\n",
    "\n",
    "# embedding the input layer\n",
    "n_tokens = len(alphabet)\n",
    "obs_embedding = EmbeddingLayer(observation_layer,\n",
    "                                              input_size=n_tokens,\n",
    "                                              output_size=n_tokens,\n",
    "                                              name = \"input_embedding\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#GRU n units\n",
    "n_hid_1 = 32\n",
    "\n",
    "#previous GRU state goes here\n",
    "prev_gru_layer = InputLayer((None,n_hid_1),name=\"prev_rnn_state\")\n",
    "\n",
    "\n",
    "# previous stack goes here\n",
    "stack_width = 3\n",
    "stack_depth = 50\n",
    "prev_stack_layer = InputLayer((None,stack_depth,stack_width))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Stack controls - push, pop and no-op\n",
    "stack_controls_layer = lasagne.layers.DenseLayer(prev_gru_layer,3,\n",
    "                                                nonlinearity= lasagne.nonlinearities.softmax,\n",
    "                                                name = \"stack controls\")\n",
    "\n",
    "# stack input\n",
    "stack_input_layer = lasagne.layers.DenseLayer(prev_gru_layer,stack_width,\n",
    "                                             nonlinearity = lasagne.nonlinearities.tanh,\n",
    "                                             name = \"stack input\")\n",
    "    \n",
    "    \n",
    "#new stack state  \n",
    "next_stack = StackAugmentation(stack_input_layer,\n",
    "                              prev_stack_layer,\n",
    "                              stack_controls_layer)\n",
    "\n",
    "\n",
    "#stack top (used for RNN)\n",
    "stack_top = lasagne.layers.SliceLayer(next_stack,0,1)\n",
    "\n",
    "\n",
    "\n",
    "#new GRU state\n",
    "gru = GRUMemoryLayer(n_hid_1,\n",
    "                     ConcatLayer([obs_embedding,stack_top]),\n",
    "                     prev_gru_layer)\n",
    "\n",
    "\n",
    "\n",
    "# Recurrent state dictionary: maps state outputs to prev_state inputs\n",
    "from collections import OrderedDict\n",
    "memory_dict = OrderedDict([\n",
    "            (gru,prev_gru_layer),\n",
    "            (next_stack, prev_stack_layer)\n",
    "    ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##Outputs\n",
    "\n",
    "# next letter probabilities\n",
    "\n",
    "probability_layer = lasagne.layers.DenseLayer(gru,\n",
    "                                         num_units = n_tokens,\n",
    "                                         nonlinearity=  lasagne.nonlinearities.softmax,\n",
    "                                         name=\"policy_original\")\n",
    "\n",
    "#resolver picks a particular letter in generation mode\n",
    "\n",
    "resolver = ProbablisticResolver(probability_layer,\n",
    "                                assume_normalized=True,\n",
    "                                name=\"resolver\")\n",
    "\n",
    "\n",
    "#verify that letter shape matches\n",
    "assert tuple(lasagne.layers.get_output_shape(resolver)) == tuple(output_shape)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Create a generator\n",
    "# - eats letters as observation, one at a time\n",
    "# - has a number of \"memory\" variables, defined by memory dict\n",
    "# - generates letters proportional to probability layer\n",
    "# - the final letter is decided at resolver layer\n",
    "\n",
    "agent = Generator(\n",
    "    observation_layer,\n",
    "    memory_dict,\n",
    "    probability_layer,\n",
    "    resolver\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unroll the recurrence\n",
    "\n",
    "* returns sessions of shape [batch_size, sequence_length, variable_size] for each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sessions = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             recorded_sequences=sequences_batch,\n",
    "                             batch_size=batch_size,)\n",
    "\n",
    "\n",
    "# rec states    -    generated letters  - predicted probabilities\n",
    "agent_states,          action_seq,           probas_seq       =  sessions\n",
    "\n",
    "\n",
    "# gru state sequence (can extract stack likewise)\n",
    "rnn_seq = agent_states[gru]\n",
    "\n",
    "\n",
    "# for this task we only need probabilities :)\n",
    "# probas_seq\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The rest is a regular lasagne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[input_embedding.W,\n",
       " stack input.W,\n",
       " stack input.b,\n",
       " stack controls.W,\n",
       " stack controls.b,\n",
       " YetAnotherGRUMemoryLayer.W_in_to_updategate,\n",
       " YetAnotherGRUMemoryLayer.W_hid_to_updategate,\n",
       " YetAnotherGRUMemoryLayer.b_updategate,\n",
       " YetAnotherGRUMemoryLayer.W_in_to_resetgate,\n",
       " YetAnotherGRUMemoryLayer.W_hid_to_resetgate,\n",
       " YetAnotherGRUMemoryLayer.b_resetgate,\n",
       " YetAnotherGRUMemoryLayer.W_in_to_hidden_update,\n",
       " YetAnotherGRUMemoryLayer.W_hid_to_hidden_update,\n",
       " YetAnotherGRUMemoryLayer.b_hidden_update,\n",
       " policy_original.W,\n",
       " policy_original.b]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Obtain them\n",
    "weights = lasagne.layers.get_all_params(resolver,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total weights: 4186\n"
     ]
    }
   ],
   "source": [
    "total_weights = int(T.sum([T.prod(w.shape) for w in weights]).eval())\n",
    "print \"Total weights:\", total_weights\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss function\n",
    "\n",
    "simple crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# take all predicitons but for last one (we don't have it's 'next')\n",
    "predicted_probas = probas_seq[:,:-1]\n",
    "\n",
    "# crop probabilities to avoid -Inf logarithms\n",
    "predicted_probas = T.maximum(predicted_probas,1e-10)\n",
    "\n",
    "# correct answers\n",
    "references = sequences_batch[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "# familiar lasagne crossentropy\n",
    "model_loss = lasagne.objectives.categorical_crossentropy(\n",
    "    predicted_probas.reshape([-1,n_tokens]),\n",
    "    references.ravel()\n",
    ").mean()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Regularizer for kicks\n",
    "from lasagne.regularization import regularize_network_params, l2\n",
    "reg_l2 = regularize_network_params(resolver,l2)*10**-5\n",
    "loss = model_loss + reg_l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "updates = lasagne.updates.adadelta(loss,weights,learning_rate=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the training and evaluation steps\n",
    "\n",
    "* Since we unroll scans, the first compile may take approx. one cup of tea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([sequences_batch],[loss],updates=updates)\n",
    "evaluation_fun = theano.function([sequences_batch],[loss,model_loss,reg_l2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating letters recurrently\n",
    "* In this mode, generator's i+1'st input is it's i-th output\n",
    "* the only difference in terms of code is that we do not provide reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generation batch size\n",
    "gen_batch_size = T.scalar('generated batch size','int32')\n",
    "\n",
    "\n",
    "_,generated_action_seq,_ = agent.get_sessions(session_length=SEQ_LENGTH,\n",
    "                             batch_size=gen_batch_size,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ~0.5 tea cups\n",
    "get_sequences = theano.function([gen_batch_size],generated_action_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#sample output\n",
    "map(alphabet.__getitem__,get_sequences(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop:\n",
    "\n",
    "* Generating sequences\n",
    "* Training on them\n",
    "* Printing metrics every once in a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "metrics = defaultdict(dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for i in range(N_EPOCHS):\n",
    "    \n",
    "    #generate reference\n",
    "    new_batch = generate_sequence(BATCH_SIZE,SEQ_LENGTH)\n",
    "    #feed the monster\n",
    "    train_fun(new_batch)\n",
    "    \n",
    "    #Display metrics once in a while\n",
    "    if i % REPORT_RATE==0:\n",
    "        \n",
    "        loss_components = evaluation_fun(new_batch)\n",
    "        print \"iter:%i\\tfull:%.5f\\tllh:%.5f\\treg:%.5f\"%tuple([i]+map(float,loss_components))        \n",
    "        \n",
    "        metrics['crossentropy'][i]=float(loss_components[1])\n",
    "        \n",
    "\n",
    "        examples = get_sequences(1000)\n",
    "        \n",
    "        correctness_ratio,c_count_mae = get_metrics(examples,alphabet)\n",
    "        \n",
    "\n",
    "        metrics[\"correctness_rates\"][i] = correctness_ratio\n",
    "        metrics[\"c_count_errors\"][i]=c_count_mae\n",
    "        \n",
    "        print \"Correct sequences ratio: %.5f\"%(correctness_ratio)\n",
    "        print \"C-s count mean abs error: %.5f\"%(c_count_mae)\n",
    "        \n",
    "        for tid_line in examples[:3]:\n",
    "            print ' '.join(map(alphabet.__getitem__,tid_line))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for metric in metrics:\n",
    "    plt.figure(figsize=[14,8])\n",
    "    plt.plot(*zip(*sorted(metrics[metric].items(),key=lambda (k,v):k)),label=metric)\n",
    "    plt.legend(loc='best')\n",
    "    plt.ylabel(\"popugai\")\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
