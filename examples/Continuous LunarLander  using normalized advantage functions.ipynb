{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### [sample solution, trained for a few hours (not converged)]\n",
    "\n",
    "# This tutorial is will bring you through your first deep reinforcement learning model\n",
    "\n",
    "\n",
    "* Seaquest game as an example\n",
    "* Training a simple lasagne neural network for Q_learning objective\n",
    "\n",
    "\n",
    "## About OpenAI Gym\n",
    "\n",
    "* Its a recently published platform that basicly allows you to train agents in a wide variety of environments with near-identical interface.\n",
    "* This is twice as awesome since now we don't need to write a new wrapper for every game\n",
    "* Go check it out!\n",
    "  * Blog post - https://openai.com/blog/openai-gym-beta/\n",
    "  * Github - https://github.com/openai/gym\n",
    "\n",
    "\n",
    "## New to Lasagne and AgentNet?\n",
    "* We only require surface level knowledge of theano and lasagne, so you can just learn them as you go.\n",
    "* Alternatively, you can find Lasagne tutorials here:\n",
    " * Official mnist example: http://lasagne.readthedocs.io/en/latest/user/tutorial.html\n",
    " * From scratch: https://github.com/ddtm/dl-course/tree/master/Seminar4\n",
    " * From theano: https://github.com/craffel/Lasagne-tutorial/blob/master/examples/tutorial.ipynb\n",
    "* This is pretty much the basic tutorial for AgentNet, so it's okay not to know it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment setup\n",
    "* Here we basically just load the game and check that it works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: THEANO_FLAGS=\"floatX=float32\"\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function \n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "%env THEANO_FLAGS=\"floatX=float32\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#global params.\n",
    "GAME = \"LunarLanderContinuous-v2\"\n",
    "\n",
    "#number of parallel agents and batch sequence length (frames)\n",
    "N_AGENTS = 1\n",
    "SEQ_LENGTH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 02:38:12,878] Making new env: LunarLanderContinuous-v2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gym\n",
    "env = gym.make(GAME)\n",
    "env.reset()\n",
    "obs = env.step(env.action_space.sample())[0]\n",
    "state_size = len(obs)\n",
    "print(obs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-1., -1.]), array([ 1.,  1.]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.low,env.action_space.high,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic agent setup\n",
    "Here we define a simple agent that maps game images into Qvalues using shallow neural network.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from lasagne.layers import InputLayer,DenseLayer,batch_norm,dropout,NonlinearityLayer,GaussianNoiseLayer,ElemwiseSumLayer\n",
    "import theano.tensor as T\n",
    "#image observation at current tick goes here, shape = (sample_i,x,y,color)\n",
    "observation_layer = InputLayer((None,state_size))\n",
    "\n",
    "dense0 = DenseLayer(observation_layer,256,name='dense1')\n",
    "dense1 = DenseLayer(dense0,256,name='dense2',nonlinearity=T.tanh,)\n",
    "\n",
    "nn = dense1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a layer that predicts Qvalues\n",
    "from agentnet.learning.qlearning_naf import LowerTriangularLayer,NAFLayer\n",
    "import theano\n",
    "epsilon = theano.shared(np.float32(0.0))\n",
    "n_actions = env.action_space.shape[0]\n",
    "low = env.action_space.low\n",
    "high = env.action_space.high\n",
    "\n",
    "class naf:\n",
    "    #predict mean\n",
    "    mean = DenseLayer(nn,n_actions,nonlinearity=None,name='mu')\n",
    "    \n",
    "    action = NonlinearityLayer(mean,lambda a: a.clip(low,high))\n",
    "    #add exploration (noize)\n",
    "    action = GaussianNoiseLayer(action,sigma=epsilon)\n",
    "    #clip back to action range\n",
    "    action = NonlinearityLayer(action,lambda a: a.clip(low,high))\n",
    "    \n",
    "    #state value (for optimal action)\n",
    "    V_layer = DenseLayer(nn,1,nonlinearity=None,name='V')\n",
    "    \n",
    "    #lower triangular matrix that describes \"variance\" term in NAF\n",
    "    L_layer = LowerTriangularLayer(nn,n_actions,name='L')\n",
    "    \n",
    "    #advantage term [negative]\n",
    "    A_layer = NAFLayer(action,mean,L_layer)\n",
    "    \n",
    "    #Q = V + A = optimal_value + negative_penalty_for_diverging_from_mean\n",
    "    qvalues_layer = ElemwiseSumLayer([V_layer,A_layer])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Finally, agent\n",
    "We declare that this network is and MDP agent with such and such inputs, states and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from agentnet.agent import Agent\n",
    "#all together\n",
    "agent = Agent(observation_layers=observation_layer,\n",
    "              policy_estimators=[naf.qvalues_layer,naf.V_layer,naf.L_layer,naf.mean],\n",
    "              action_layers=naf.action)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[dense1.W,\n",
       " dense1.b,\n",
       " dense2.W,\n",
       " dense2.b,\n",
       " V.W,\n",
       " V.b,\n",
       " mu.W,\n",
       " mu.b,\n",
       " L.preprocess_input.W,\n",
       " L.preprocess_input.b]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Since it's a single lasagne network, one can get it's weights, output, etc\n",
    "weights = lasagne.layers.get_all_params(naf.qvalues_layer,trainable=True)\n",
    "weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and manage a pool of atari sessions to play with\n",
    "\n",
    "* To make training more stable, we shall have an entire batch of game sessions each happening independent of others\n",
    "* Why several parallel agents help training: http://arxiv.org/pdf/1602.01783v1.pdf\n",
    "* Alternative approach: store more sessions: https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 02:38:37,524] Making new env: LunarLanderContinuous-v2\n"
     ]
    }
   ],
   "source": [
    "from agentnet.experiments.openai_gym.pool import EnvPool\n",
    "\n",
    "pool = EnvPool(agent,GAME, N_AGENTS,max_size=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 0.03422687  0.22225321]\n",
      "  [ 0.07668241 -0.00301102]\n",
      "  [-0.21279974 -0.10377608]\n",
      "  [-0.07751393 -0.107909  ]\n",
      "  [ 0.02133946 -0.03888784]\n",
      "  [ 0.11148803 -0.04626344]\n",
      "  [ 0.02013578 -0.07525788]\n",
      "  [-0.04302869 -0.02809524]\n",
      "  [-0.12381561 -0.02354189]\n",
      "  [ 0.20552675  0.08976637]]]\n",
      "[[-0.78526392 -1.85882304  0.62372596  0.56684725 -1.0229405  -0.78501682\n",
      "  -1.53121011  0.48440251  0.41025322  0.        ]]\n",
      "CPU times: user 628 ms, sys: 20 ms, total: 648 ms\n",
      "Wall time: 239 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#interact for 7 ticks\n",
    "_,action_log,reward_log,_,_,_  = pool.interact(10)\n",
    "\n",
    "\n",
    "print(action_log)\n",
    "print(reward_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#load first sessions (this function calls interact and remembers sessions)\n",
    "pool.update(SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Q-learning\n",
    "* An agent has a method that produces symbolic environment interaction sessions\n",
    "* Such sessions are in sequences of observations, agent memory, actions, q-values,etc\n",
    "  * one has to pre-define maximum session length.\n",
    "\n",
    "* SessionPool also stores rewards (Q-learning objective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get agent's Qvalues obtained via experience replay\n",
    "replay = pool.experience_replay.sample_session_batch(100,replace=True)\n",
    "\n",
    "_,_,_,_,(action_qvalues_seq,optimal_qvalues_seq,l_term,mu_term) = agent.get_sessions(\n",
    "    replay,\n",
    "    session_length=SEQ_LENGTH,\n",
    "    experience_replay=True,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get reference Qvalues according to Qlearning algorithm\n",
    "from agentnet.learning.qlearning_naf import get_elementwise_objective\n",
    "\n",
    "#loss for Qlearning = (Q(s,a) - (r+gamma*Q(s',a_max)))^2\n",
    "elwise_mse_loss = get_elementwise_objective(action_qvalues_seq[:,:,0],\n",
    "                                            optimal_qvalues_seq[:,:,0],\n",
    "                                            replay.rewards,\n",
    "                                            replay.is_alive,\n",
    "                                            gamma_or_gammas=0.99,)\n",
    "\n",
    "#compute mean over \"alive\" fragments\n",
    "loss = elwise_mse_loss.sum() / replay.is_alive.sum()\n",
    "#add l2 regularizer\n",
    "loss += lasagne.regularization.regularize_network_params(nn,lasagne.regularization.l2)*1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute weight updates\n",
    "updates = lasagne.updates.adam(loss,weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#compile train function\n",
    "import theano\n",
    "train_step = theano.function([],loss,updates=updates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 02:39:05,834] Making new env: LunarLanderContinuous-v2\n",
      "[2016-12-14 02:39:05,839] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2016-12-14 02:39:05,841] Starting new video recorder writing to /root/test/continuous/records/openaigym.video.0.371974.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 75 timesteps with reward=-199.433403439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 02:39:08,982] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/test/continuous/records')\n"
     ]
    }
   ],
   "source": [
    "#for MountainCar-v0 evaluation session is cropped to 200 ticks\n",
    "untrained_reward = pool.evaluate(save_path=\"./records\",record_video=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<video width=\"640\" height=\"480\" controls>\n",
       "  <source src=\"records/openaigym.video.3.166090.video000000.mp4\" type=\"video/mp4\">\n",
       "</video>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import HTML\n",
    "#!TODO add url\n",
    "video_path=\"records/openaigym.video.0.371974.video000000.mp4\" #<-- paste link from previous cell starting from records\n",
    "\n",
    "HTML(\"\"\"\n",
    "<video width=\"640\" height=\"480\" controls>\n",
    "  <source src=\"{}\" type=\"video/mp4\">\n",
    "</video>\n",
    "\"\"\".format(video_path))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#starting epoch\n",
    "epoch_counter = 1\n",
    "loss=train_step()\n",
    "\n",
    "\n",
    "#full game rewards\n",
    "rewards = {epoch_counter:untrained_reward}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:13<00:00, 75.46it/s]\n"
     ]
    }
   ],
   "source": [
    "#pre-fill pool\n",
    "from tqdm import tqdm\n",
    "for i in tqdm(range(1000)):\n",
    "    pool.update(SEQ_LENGTH,append=True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 79/10000 [02:31<4:23:24,  1.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3800\tloss=70.977\tepsilon=0.100\treward/step=-1.02659\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 179/10000 [04:27<1:23:21,  1.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=3900\tloss=50.060\tepsilon=0.100\treward/step=-0.72148\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 278/10000 [05:54<4:26:14,  1.64s/it][2016-12-14 04:21:23,804] Making new env: LunarLanderContinuous-v2\n",
      "[2016-12-14 04:21:23,809] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4000\tloss=35.338\tepsilon=0.100\treward/step=-0.56612\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:22:08,439] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/test/continuous/records')\n",
      "  3%|▎         | 279/10000 [06:41<40:49:03, 15.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -165.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 379/10000 [07:57<1:30:16,  1.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4100\tloss=23.550\tepsilon=0.100\treward/step=-0.44988\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 479/10000 [08:57<1:14:25,  2.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4200\tloss=31.976\tepsilon=0.100\treward/step=-0.46752\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 579/10000 [09:39<1:04:25,  2.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4300\tloss=59.696\tepsilon=0.100\treward/step=-0.77709\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 679/10000 [10:21<1:02:01,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4400\tloss=95.235\tepsilon=0.100\treward/step=-1.22547\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 778/10000 [11:06<1:10:14,  2.19it/s][2016-12-14 04:26:34,682] Making new env: LunarLanderContinuous-v2\n",
      "[2016-12-14 04:26:34,687] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4500\tloss=111.045\tepsilon=0.100\treward/step=-1.45352\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:26:35,363] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/test/continuous/records')\n",
      "  8%|▊         | 779/10000 [11:07<1:37:21,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -534.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 879/10000 [11:48<1:05:05,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4600\tloss=145.347\tepsilon=0.100\treward/step=-1.69639\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 979/10000 [12:30<1:03:00,  2.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4700\tloss=156.585\tepsilon=0.100\treward/step=-1.88982\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1079/10000 [13:14<57:12,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4800\tloss=177.128\tepsilon=0.100\treward/step=-2.00173\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 1179/10000 [14:14<1:01:46,  2.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=4900\tloss=182.537\tepsilon=0.100\treward/step=-2.07024\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1278/10000 [15:08<2:22:02,  1.02it/s][2016-12-14 04:30:37,415] Making new env: LunarLanderContinuous-v2\n",
      "[2016-12-14 04:30:37,419] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5000\tloss=207.330\tepsilon=0.100\treward/step=-2.13864\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:30:40,263] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/test/continuous/records')\n",
      " 13%|█▎        | 1279/10000 [15:12<4:29:12,  1.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -316.719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1379/10000 [16:01<1:09:17,  2.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5100\tloss=198.018\tepsilon=0.100\treward/step=-2.20260\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 1479/10000 [19:41<1:44:47,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5200\tloss=194.368\tepsilon=0.100\treward/step=-2.09470\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1579/10000 [20:41<1:31:52,  1.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5300\tloss=163.186\tepsilon=0.100\treward/step=-1.75315\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 1679/10000 [21:49<1:03:10,  2.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5400\tloss=138.089\tepsilon=0.100\treward/step=-1.33641\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1778/10000 [23:07<1:14:06,  1.85it/s][2016-12-14 04:38:35,982] Making new env: LunarLanderContinuous-v2\n",
      "[2016-12-14 04:38:35,987] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5500\tloss=121.250\tepsilon=0.100\treward/step=-1.14887\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:38:40,534] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/test/continuous/records')\n",
      " 18%|█▊        | 1779/10000 [23:13<4:34:51,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -242.271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1879/10000 [24:31<1:04:57,  2.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5600\tloss=102.322\tepsilon=0.100\treward/step=-0.96360\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 1979/10000 [25:33<57:17,  2.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5700\tloss=82.159\tepsilon=0.100\treward/step=-0.86608\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 2079/10000 [26:25<54:35,  2.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5800\tloss=83.814\tepsilon=0.100\treward/step=-0.90250\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2179/10000 [27:26<2:12:34,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=5900\tloss=84.593\tepsilon=0.100\treward/step=-0.93049\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 2278/10000 [28:24<1:29:24,  1.44it/s][2016-12-14 04:43:52,248] Making new env: LunarLanderContinuous-v2\n",
      "[2016-12-14 04:43:52,252] Clearing 2 monitor files from previous run (because force=True was provided)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter=6000\tloss=81.875\tepsilon=0.100\treward/step=-0.90980\tpool_size=10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:43:55,603] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/test/continuous/records')\n",
      " 23%|██▎       | 2279/10000 [28:28<3:41:00,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current score(mean over 10) = -295.074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▎       | 2350/10000 [29:18<1:04:23,  1.98it/s]"
     ]
    }
   ],
   "source": [
    "epsilon.set_value(0.1)\n",
    "#the loop may take eons to finish.\n",
    "#consider interrupting early.\n",
    "for i in tqdm(range(10000)):    \n",
    "    \n",
    "    \n",
    "    #train\n",
    "    for i in range(10):\n",
    "        pool.update(SEQ_LENGTH,append=True,)\n",
    "        \n",
    "    for i in range(10):\n",
    "        loss = loss * 0.99 + train_step()*0.01\n",
    "    \n",
    "    \n",
    "    \n",
    "    if epoch_counter%100==0:\n",
    "        #average reward per game tick in current experience replay pool\n",
    "        pool_mean_reward = np.average(pool.experience_replay.rewards.get_value()[:,:-1],\n",
    "                                      weights=pool.experience_replay.is_alive.get_value()[:,:-1])\n",
    "        pool_size = pool.experience_replay.rewards.get_value().shape[0]\n",
    "        print(\"iter=%i\\tloss=%.3f\\tepsilon=%.3f\\treward/step=%.5f\\tpool_size=%i\"%(epoch_counter,\n",
    "                                                                                  loss,\n",
    "                                                                                  epsilon.get_value(),\n",
    "                                                                                  pool_mean_reward,\n",
    "                                                                                  pool_size))\n",
    "        \n",
    "\n",
    "    ##record current learning progress and show learning curves\n",
    "    if epoch_counter%500 ==0:\n",
    "        n_games = 10\n",
    "        epsilon.set_value(0)\n",
    "        rewards[epoch_counter] = pool.evaluate( record_video=False,n_games=n_games,verbose=False)\n",
    "        print(\"Current score(mean over %i) = %.3f\"%(n_games,np.mean(rewards[epoch_counter])))\n",
    "        epsilon.set_value(0.1)\n",
    "        \n",
    "    #if you see sudden slowdowns after few thousand iterations, it means box2d issue is still not fixed\n",
    "    #use this line to reset it time to time:\n",
    "    #pool.envs[0] = gym.make(GAME)\n",
    "    \n",
    "    \n",
    "    epoch_counter  +=1\n",
    "\n",
    "    \n",
    "# Time to drink some coffee!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/ipykernel/__main__.py:3: FutureWarning: pd.ewm_mean is deprecated for ndarrays and will be removed in a future version\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ff24a0cd410>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiIAAAFkCAYAAAAdXVDGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff258fef610>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ticks,r = zip(*sorted(rewards.items(),key=lambda (k,v): k))\n",
    "plt.plot(ticks,pd.ewma(np.array(map(np.mean,r)),alpha=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:12:23,454] Making new env: LunarLanderContinuous-v2\n",
      "[2016-12-14 04:12:23,470] Clearing 2 monitor files from previous run (because force=True was provided)\n",
      "[2016-12-14 04:12:23,476] Starting new video recorder writing to /root/test/continuous/records/openaigym.video.8.371974.video000000.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-110.875128203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:12:46,744] Starting new video recorder writing to /root/test/continuous/records/openaigym.video.8.371974.video000001.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-99.9381066687\n",
      "Episode finished after 1000 timesteps with reward=-99.010162853\n",
      "Episode finished after 1000 timesteps with reward=-121.029896323\n",
      "Episode finished after 1000 timesteps with reward=-82.7363235336\n",
      "Episode finished after 1000 timesteps with reward=-100.427231227\n",
      "Episode finished after 1000 timesteps with reward=-62.5335570436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:14:01,278] Starting new video recorder writing to /root/test/continuous/records/openaigym.video.8.371974.video000008.mp4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-112.624933727\n",
      "Episode finished after 1000 timesteps with reward=-90.5384471249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2016-12-14 04:14:36,906] Finished writing results. You can upload them to the scoreboard via gym.upload('/root/test/continuous/records')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode finished after 1000 timesteps with reward=-88.8171271279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[-110.87512820265022,\n",
       " -99.938106668678671,\n",
       " -99.010162853010826,\n",
       " -121.02989632301791,\n",
       " -82.736323533555364,\n",
       " -100.42723122660394,\n",
       " -62.533557043576607,\n",
       " -112.62493372678664,\n",
       " -90.538447124939253,\n",
       " -88.817127127869114]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool.evaluate(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "optimal_qvalues_seq.eval()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
